{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763a51be-0dda-4988-bf32-aaa864c93f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1f640a3-399b-45f7-a2b1-af400324541c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting neo4j\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/04/00/1f74089c06aec1fac9390e2300a6a6b2381e0dac281783d64ccca9d681fd/neo4j-5.28.2-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pytz (from neo4j)\n",
      "  Using cached http://mirrors.aliyun.com/pypi/packages/81/c4/34e93fe5f5429d7570ec1fa436f1986fb1f00c3e0f43a589fe2bbcd22c3f/pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Installing collected packages: pytz, neo4j\n",
      "Successfully installed neo4j-5.28.2 pytz-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df571898-4cbd-455e-9194-08863f023535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Collecting pandas\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/da/01/e383018feba0a1ead6cf5fe8728e5d767fee02f06a3d800e82c489e5daaf/pandas-2.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.0 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.26.0 in /root/miniconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /root/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /root/miniconda3/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading http://mirrors.aliyun.com/pypi/packages/5c/23/c7abc0ca0a1526a0774eca151daeb8de62ec457e77262b66b359c3c7679e/tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /root/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.3.1 tzdata-2025.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ea103a-926b-488f-9735-3cfde26f5ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: tqdm in /root/miniconda3/lib/python3.12/site-packages (4.66.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3283794f-73b3-493b-ab08-0d02a1ed42a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â∑≤Á°Æ‰øùOrderIDÁöÑÂîØ‰∏ÄÊÄßÁ∫¶Êùü\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÂØºÂÖ•ËøõÂ∫¶: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÊàêÂäüÂØºÂÖ• 100 Êù°ËÆ¢ÂçïÊï∞ÊçÆÔºàÂ∑≤Ëá™Âä®ÂéªÈáçÔºâ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "from tqdm import tqdm  # ËøõÂ∫¶Êù°Â∑•ÂÖ∑ÔºàÂèØÈÄâÔºâ\n",
    "\n",
    "# Neo4j AuraDB ËøûÊé•ÈÖçÁΩÆ\n",
    "URI = \"neo4j+s://68689680.databases.neo4j.io\"\n",
    "USER = \"neo4j\"\n",
    "PASSWORD = \"IubLSzByNDoUMEg_LCBZe9zQ_DXZuzNubNX8QL_lyO0\"\n",
    "\n",
    "def create_constraint(session):\n",
    "    \"\"\"ÂàõÂª∫OrderIDÁöÑÂîØ‰∏ÄÊÄßÁ∫¶Êùü\"\"\"\n",
    "    session.run(\"\"\"\n",
    "    CREATE CONSTRAINT order_id_unique IF NOT EXISTS \n",
    "    FOR (o:Order) REQUIRE o.orderID IS UNIQUE\n",
    "    \"\"\")\n",
    "    print(\"Â∑≤Á°Æ‰øùOrderIDÁöÑÂîØ‰∏ÄÊÄßÁ∫¶Êùü\")\n",
    "\n",
    "def import_orders():\n",
    "    driver = GraphDatabase.driver(URI, auth=(USER, PASSWORD))\n",
    "    \n",
    "    try:\n",
    "        # 1. È¶ñÂÖàÂàõÂª∫Á∫¶Êùü\n",
    "        with driver.session() as session:\n",
    "            create_constraint(session)\n",
    "        \n",
    "        # 2. ËØªÂèñÂπ∂È¢ÑÂ§ÑÁêÜÊï∞ÊçÆ\n",
    "        df = pd.read_csv(\"exported_data/orders.csv\")\n",
    "        df = df.where(pd.notnull(df), None)  # Â§ÑÁêÜÁ©∫ÂÄº\n",
    "        \n",
    "        # 3. ÊâπÈáèÂØºÂÖ•ÔºàÂ∏¶ÂÜ≤Á™ÅÂ§ÑÁêÜÔºâ\n",
    "        with driver.session() as session:\n",
    "            # ‰ΩøÁî®UNWIND + MERGEÁ°Æ‰øù‰∏çÈáçÂ§çÊèíÂÖ•\n",
    "            query = \"\"\"\n",
    "            UNWIND $orders AS order\n",
    "            MERGE (o:Order {orderID: order.OrderID})\n",
    "            ON CREATE SET\n",
    "                o.orderDate = order.OrderDate,\n",
    "                o.requiredDate = order.RequiredDate,\n",
    "                o.shippedDate = order.ShippedDate,\n",
    "                o.freight = toFloat(order.Freight),\n",
    "                o.shipName = order.ShipName,\n",
    "                o.shipAddress = order.ShipAddress,\n",
    "                o.shipCity = order.ShipCity,\n",
    "                o.shipRegion = order.ShipRegion,\n",
    "                o.shipPostalCode = order.ShipPostalCode,\n",
    "                o.shipCountry = order.ShipCountry\n",
    "            \"\"\"\n",
    "            \n",
    "            # ÂàÜÊâπÂØºÂÖ•ÔºàÊØèÊâπ1000Êù°Ôºâ\n",
    "            batch_size = 1000\n",
    "            for i in tqdm(range(0, len(df), batch_size), desc=\"ÂØºÂÖ•ËøõÂ∫¶\"):\n",
    "                batch = df.iloc[i:i+batch_size].to_dict('records')\n",
    "                session.run(query, parameters={\"orders\": batch})\n",
    "            \n",
    "            print(f\"ÊàêÂäüÂØºÂÖ• {len(df)} Êù°ËÆ¢ÂçïÊï∞ÊçÆÔºàÂ∑≤Ëá™Âä®ÂéªÈáçÔºâ\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ÈîôËØØ: {str(e)}\")\n",
    "    finally:\n",
    "        driver.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_orders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33851c1a-b78e-44f1-bb77-e58f9da30c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Â∑≤Á°Æ‰øùShipperIDÁöÑÂîØ‰∏ÄÊÄßÁ∫¶Êùü\n",
      "ÊàêÂäüÂ§ÑÁêÜ 10 Êù°Ë¥ßËøêÂÖ¨Âè∏Êï∞ÊçÆ\n",
      "ÂÆûÈôÖÊñ∞Â¢ûËäÇÁÇπ: 10\n",
      "Ë∑≥ËøáÈáçÂ§çËäÇÁÇπ: 0\n",
      "Êï∞ÊçÆÂ∫ìËøûÊé•Â∑≤ÂÆâÂÖ®ÂÖ≥Èó≠\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "\n",
    "# Neo4j AuraDB ËøûÊé•ÈÖçÁΩÆÔºàÊ≥®ÊÑèÔºöÂª∫ËÆÆÂ∞ÜÂØÜÁ†ÅÁßªÂá∫‰ª£Á†ÅÔºå‰ΩøÁî®ÁéØÂ¢ÉÂèòÈáèÔºâ\n",
    "URI = \"neo4j+s://68689680.databases.neo4j.io\"\n",
    "USER = \"neo4j\"\n",
    "PASSWORD = \"IubLSzByNDoUMEg_LCBZe9zQ_DXZuzNubNX8QL_lyO0\"  # ËØ∑Â∞ΩÂø´‰øÆÊîπÂØÜÁ†ÅÂπ∂ÈÅøÂÖçÂÖ¨ÂºÄ\n",
    "\n",
    "def create_shipper_constraint(session):\n",
    "    \"\"\"ÂàõÂª∫ShipperIDÁöÑÂîØ‰∏ÄÊÄßÁ∫¶Êùü\"\"\"\n",
    "    session.run(\"\"\"\n",
    "    CREATE CONSTRAINT shipper_id_unique IF NOT EXISTS \n",
    "    FOR (s:Shipper) REQUIRE s.ShipperID IS UNIQUE\n",
    "    \"\"\")\n",
    "    print(\"Â∑≤Á°Æ‰øùShipperIDÁöÑÂîØ‰∏ÄÊÄßÁ∫¶Êùü\")\n",
    "\n",
    "def import_shippers():\n",
    "    # ÂàùÂßãÂåñÈ©±Âä®\n",
    "    driver = GraphDatabase.driver(URI, auth=(USER, PASSWORD))\n",
    "    \n",
    "    try:\n",
    "        # 1. ËØªÂèñCSVÊñá‰ª∂\n",
    "        df = pd.read_csv(\"exported_data/shippers.csv\")\n",
    "        \n",
    "        # 2. Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÔºöÊèêÂèñÊâÄÈúÄÂàóÂπ∂ÂéªÈáç\n",
    "        shipper_df = df[['ShipperID', 'CompanyName', 'Phone']].drop_duplicates()\n",
    "        \n",
    "        # 3. ÂàõÂª∫Á∫¶ÊùüÂπ∂ÂØºÂÖ•Êï∞ÊçÆ\n",
    "        with driver.session() as session:\n",
    "            # È¶ñÂÖàÂàõÂª∫ÂîØ‰∏ÄÁ∫¶Êùü\n",
    "            create_shipper_constraint(session)\n",
    "            \n",
    "            # ‰ΩøÁî®MERGEÈÅøÂÖçÈáçÂ§çÊèíÂÖ•\n",
    "            query = \"\"\"\n",
    "            UNWIND $shippers AS shipper\n",
    "            MERGE (s:Shipper {ShipperID: shipper.ShipperID})\n",
    "            ON CREATE SET\n",
    "                s.CompanyName = shipper.CompanyName,\n",
    "                s.Phone = shipper.Phone\n",
    "            \"\"\"\n",
    "            \n",
    "            # ËΩ¨Êç¢‰∏∫Â≠óÂÖ∏ÂàóË°®Âπ∂ÊâπÈáèÊèê‰∫§\n",
    "            shippers_data = shipper_df.to_dict('records')\n",
    "            result = session.run(query, parameters={\"shippers\": shippers_data})\n",
    "            \n",
    "            # Ëé∑ÂèñÁªüËÆ°‰ø°ÊÅØ\n",
    "            summary = result.consume()\n",
    "            print(f\"ÊàêÂäüÂ§ÑÁêÜ {len(shippers_data)} Êù°Ë¥ßËøêÂÖ¨Âè∏Êï∞ÊçÆ\")\n",
    "            print(f\"ÂÆûÈôÖÊñ∞Â¢ûËäÇÁÇπ: {summary.counters.nodes_created}\")\n",
    "            print(f\"Ë∑≥ËøáÈáçÂ§çËäÇÁÇπ: {len(shippers_data) - summary.counters.nodes_created}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ÂØºÂÖ•ËøáÁ®ã‰∏≠ÂèëÁîüÈîôËØØ: {e}\")\n",
    "    finally:\n",
    "        driver.close()\n",
    "        print(\"Êï∞ÊçÆÂ∫ìËøûÊé•Â∑≤ÂÆâÂÖ®ÂÖ≥Èó≠\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import_shippers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5531186-5b25-4773-9db6-63041cd39c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a962b7-1fc9-4834-bc0b-5cc56ff1f01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Ê≠£Âú®ËØªÂèñemployee.csvÊñá‰ª∂...\n",
      "‚úÖ Â∑≤Á°Æ‰øùEmployeeIDÁöÑÂîØ‰∏ÄÊÄßÁ∫¶Êùü\n",
      "üìä ÂÖ±ÂèëÁé∞ 3 Êù°ÂëòÂ∑•ËÆ∞ÂΩï\n",
      "‚è≥ Â∑≤Â§ÑÁêÜ 3/3 Êù°\n",
      "üéâ ÂëòÂ∑•Êï∞ÊçÆÂØºÂÖ•ÂÆåÊàêÔºÅ\n",
      "üîí Êï∞ÊçÆÂ∫ìËøûÊé•Â∑≤ÂÆâÂÖ®ÂÖ≥Èó≠\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ÂÆâÂÖ®ÊèêÁ§∫ÔºöÂª∫ËÆÆ‰ΩøÁî®ÁéØÂ¢ÉÂèòÈáèÂ≠òÂÇ®ÊïèÊÑü‰ø°ÊÅØ\n",
    "# Âú®ËøêË°åÂâçËØ∑ËÆæÁΩÆÁéØÂ¢ÉÂèòÈáèÔºöexport NEO4J_PASSWORD=\"your_password\"\n",
    "URI = \"neo4j+s://68689680.databases.neo4j.io\"\n",
    "USER = \"neo4j\"\n",
    "PASSWORD = os.getenv(\"NEO4J_PASSWORD\", \"IubLSzByNDoUMEg_LCBZe9zQ_DXZuzNubNX8QL_lyO0\")\n",
    "\n",
    "def create_employee_constraint(session):\n",
    "    \"\"\"ÂàõÂª∫EmployeeIDÁöÑÂîØ‰∏ÄÊÄßÁ∫¶Êùü\"\"\"\n",
    "    session.run(\"\"\"\n",
    "    CREATE CONSTRAINT employee_id_unique IF NOT EXISTS\n",
    "    FOR (e:Employee) REQUIRE e.EmployeeID IS UNIQUE\n",
    "    \"\"\")\n",
    "    print(\"‚úÖ Â∑≤Á°Æ‰øùEmployeeIDÁöÑÂîØ‰∏ÄÊÄßÁ∫¶Êùü\")\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"Êï∞ÊçÆÊ∏ÖÊ¥óÂáΩÊï∞\"\"\"\n",
    "    # Â§ÑÁêÜÊó•ÊúüÊ†ºÂºèÔºàÂÅáËÆæCSV‰∏≠ÊòØÂ≠óÁ¨¶‰∏≤Ê†ºÂºèÂ¶Ç'1994-05-23'Ôºâ\n",
    "    date_columns = ['BirthDate', 'HireDate']\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Â§ÑÁêÜÁ©∫ÂÄº\n",
    "    df = df.replace({pd.NA: None, '': None})\n",
    "    return df\n",
    "\n",
    "def import_employees():\n",
    "    driver = GraphDatabase.driver(URI, auth=(USER, PASSWORD))\n",
    "    \n",
    "    try:\n",
    "        print(\"üîÑ Ê≠£Âú®ËØªÂèñemployee.csvÊñá‰ª∂...\")\n",
    "        df = pd.read_csv(\"exported_data/employees.csv\")\n",
    "        \n",
    "        # Êï∞ÊçÆÊ∏ÖÊ¥ó\n",
    "        df = clean_data(df)\n",
    "        \n",
    "        with driver.session() as session:\n",
    "            # 1. ÂàõÂª∫Á∫¶Êùü\n",
    "            create_employee_constraint(session)\n",
    "            \n",
    "            # 2. ÂáÜÂ§áÊâπÈáèÂØºÂÖ•Êü•ËØ¢\n",
    "            query = \"\"\"\n",
    "            UNWIND $employees AS emp\n",
    "            MERGE (e:Employee {EmployeeID: emp.EmployeeID})\n",
    "            ON CREATE SET\n",
    "                e.LastName = emp.LastName,\n",
    "                e.FirstName = emp.FirstName,\n",
    "                e.Title = emp.Title,\n",
    "                e.BirthDate = date(emp.BirthDate),\n",
    "                e.HireDate = date(emp.HireDate),\n",
    "                e.Address = emp.Address,\n",
    "                e.City = emp.City,\n",
    "                e.Country = emp.Country,\n",
    "                e.HomePhone = emp.HomePhone,\n",
    "                e.Notes = emp.Notes\n",
    "            \"\"\"\n",
    "            \n",
    "            # 3. ÂàÜÊâπÂØºÂÖ•ÔºàÊØèÊâπ500Êù°Ôºâ\n",
    "            batch_size = 500\n",
    "            total = len(df)\n",
    "            print(f\"üìä ÂÖ±ÂèëÁé∞ {total} Êù°ÂëòÂ∑•ËÆ∞ÂΩï\")\n",
    "            \n",
    "            for i in range(0, total, batch_size):\n",
    "                batch = df.iloc[i:i+batch_size].to_dict('records')\n",
    "                session.run(query, parameters={\"employees\": batch})\n",
    "                print(f\"‚è≥ Â∑≤Â§ÑÁêÜ {min(i+batch_size, total)}/{total} Êù°\")\n",
    "            \n",
    "            print(\"üéâ ÂëòÂ∑•Êï∞ÊçÆÂØºÂÖ•ÂÆåÊàêÔºÅ\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ÂØºÂÖ•ËøáÁ®ã‰∏≠ÂèëÁîüÈîôËØØ: {str(e)}\")\n",
    "    finally:\n",
    "        driver.close()\n",
    "        print(\"üîí Êï∞ÊçÆÂ∫ìËøûÊé•Â∑≤ÂÆâÂÖ®ÂÖ≥Èó≠\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ÂÆâÂÖ®Ê£ÄÊü•\n",
    "    if not PASSWORD:\n",
    "        print(\"‚ö†Ô∏è ÈîôËØØÔºöÊú™Ê£ÄÊµãÂà∞Êï∞ÊçÆÂ∫ìÂØÜÁ†ÅÔºÅËØ∑ËÆæÁΩÆNEO4J_PASSWORDÁéØÂ¢ÉÂèòÈáè\")\n",
    "        exit(1)\n",
    "    \n",
    "    import_employees()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15375be4-0bd5-4c93-a1f4-77a1a79fd52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2698c4da-925d-4027-b7bc-0b010a584b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Êï∞ÊçÆÂ∫ìÁ∫¶ÊùüÂ∑≤Â∞±Áª™\n",
      "ÂºÄÂßãÂØºÂÖ• 20 Êù°ÂÆ¢Êà∑ËÆ∞ÂΩï...\n",
      "ÂØºÂÖ•ÂÆåÊàêÔºÅÊñ∞Â¢û 20 Êù°ËÆ∞ÂΩï\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ÂÆâÂÖ®ÈÖçÁΩÆÔºàÂª∫ËÆÆÈÄöËøáÁéØÂ¢ÉÂèòÈáèËÆæÁΩÆÂØÜÁ†ÅÔºâ\n",
    "NEO4J_URI = os.getenv(\"NEO4J_URI\", \"neo4j+s://68689680.databases.neo4j.io\")\n",
    "NEO4J_USER = os.getenv(\"NEO4J_USER\", \"neo4j\")\n",
    "NEO4J_PASSWORD =\"IubLSzByNDoUMEg_LCBZe9zQ_DXZuzNubNX8QL_lyO0\"  # ÂøÖÈ°ªÈÄöËøáÁéØÂ¢ÉÂèòÈáèËÆæÁΩÆ\n",
    "\n",
    "def validate_env():\n",
    "    \"\"\"È™åËØÅÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ\"\"\"\n",
    "    if not NEO4J_PASSWORD:\n",
    "        raise ValueError(\"Êú™Ê£ÄÊµãÂà∞Êï∞ÊçÆÂ∫ìÂØÜÁ†ÅÔºÅËØ∑ËÆæÁΩÆNEO4J_PASSWORDÁéØÂ¢ÉÂèòÈáè\")\n",
    "\n",
    "class Neo4jCustomerImporter:\n",
    "    def __init__(self):\n",
    "        self.driver = GraphDatabase.driver(\n",
    "            NEO4J_URI,\n",
    "            auth=(NEO4J_USER, NEO4J_PASSWORD),\n",
    "            max_connection_lifetime=30*60,\n",
    "            connection_timeout=15  # 15ÁßíËøûÊé•Ë∂ÖÊó∂\n",
    "        )\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def create_constraints(self):\n",
    "        \"\"\"ÂàõÂª∫Êï∞ÊçÆÂ∫ìÁ∫¶Êùü\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            session.execute_write(lambda tx: tx.run(\"\"\"\n",
    "                CREATE CONSTRAINT customer_id_unique IF NOT EXISTS\n",
    "                FOR (c:Customer) REQUIRE c.CustomerID IS UNIQUE\n",
    "                \"\"\"))\n",
    "            print(\"Êï∞ÊçÆÂ∫ìÁ∫¶ÊùüÂ∑≤Â∞±Áª™\")\n",
    "\n",
    "    def preprocess_data(self, file_path):\n",
    "        \"\"\"Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ\"\"\"\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # ÂàóÂêçÊ†áÂáÜÂåñÂ§ÑÁêÜ\n",
    "        df.columns = df.columns.str.strip()\n",
    "        \n",
    "        # Á©∫ÂÄºÂ§ÑÁêÜ\n",
    "        df = df.replace({pd.NA: None, '': None, 'NULL': None})\n",
    "        \n",
    "        # Â≠óÁ¨¶‰∏≤Â≠óÊÆµÊ∏ÖÁêÜ\n",
    "        string_cols = ['CompanyName', 'ContactName', 'ContactTitle']\n",
    "        for col in string_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].str.strip()\n",
    "        \n",
    "        # È™åËØÅÂøÖÈúÄÂ≠óÊÆµ\n",
    "        required_fields = ['CustomerID', 'CompanyName']\n",
    "        missing_fields = [f for f in required_fields if f not in df.columns]\n",
    "        if missing_fields:\n",
    "            raise ValueError(f\"CSVÊñá‰ª∂Áº∫Â∞ëÂøÖÈúÄÂ≠óÊÆµ: {missing_fields}\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def import_data(self, df):\n",
    "        \"\"\"ÊâßË°åÊï∞ÊçÆÂØºÂÖ•\"\"\"\n",
    "        total = len(df)\n",
    "        print(f\"ÂºÄÂßãÂØºÂÖ• {total} Êù°ÂÆ¢Êà∑ËÆ∞ÂΩï...\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # ‰ΩøÁî®Ëá™Âä®Êèê‰∫§‰∫ãÂä°Ôºàauto-commitÔºâÊèêÈ´òÊÄßËÉΩ\n",
    "            result = session.run(\"\"\"\n",
    "                UNWIND $customers AS row\n",
    "                MERGE (c:Customer {CustomerID: row.CustomerID})\n",
    "                ON CREATE SET\n",
    "                    c.CompanyName = row.CompanyName,\n",
    "                    c.ContactName = row.ContactName,\n",
    "                    c.ContactTitle = row.ContactTitle,\n",
    "                    c.Address = row.Address,\n",
    "                    c.City = row.City,\n",
    "                    c.Region = row.Region,\n",
    "                    c.PostalCode = row.PostalCode,\n",
    "                    c.Country = row.Country,\n",
    "                    c.Phone = row.Phone,\n",
    "                    c.Fax = row.Fax\n",
    "                RETURN count(c)\n",
    "                \"\"\", {\"customers\": df.to_dict('records')})\n",
    "            \n",
    "            inserted = result.single()[0]\n",
    "            print(f\"ÂØºÂÖ•ÂÆåÊàêÔºÅÊñ∞Â¢û {inserted} Êù°ËÆ∞ÂΩï\")\n",
    "            if inserted < total:\n",
    "                print(f\"Ê≥®ÊÑèÔºöË∑≥Ëøá {total - inserted} Êù°ÈáçÂ§çËÆ∞ÂΩï\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        validate_env()\n",
    "        \n",
    "        with Neo4jCustomerImporter() as importer:\n",
    "            # 1. ÂàõÂª∫Á∫¶Êùü\n",
    "            importer.create_constraints()\n",
    "            \n",
    "            # 2. Âä†ËΩΩÂπ∂È¢ÑÂ§ÑÁêÜÊï∞ÊçÆ\n",
    "            df = importer.preprocess_data(\"exported_data/customers.csv\")\n",
    "            \n",
    "            # 3. ÊâßË°åÂØºÂÖ•\n",
    "            importer.import_data(df)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ÈîôËØØ: {str(e)}\")\n",
    "        if isinstance(e, pd.errors.EmptyDataError):\n",
    "            print(\"ËØ∑Ê£ÄÊü•CSVÊñá‰ª∂ÊòØÂê¶‰∏∫Á©∫ÊàñÊ†ºÂºè‰∏çÊ≠£Á°Æ\")\n",
    "        elif isinstance(e, FileNotFoundError):\n",
    "            print(\"Êñá‰ª∂Ë∑ØÂæÑÈîôËØØÔºåËØ∑Á°ÆËÆ§exported_data/customers.csvÊòØÂê¶Â≠òÂú®\")\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exit(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523cfb3-ef8b-4113-b74e-2dd928b9ec3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d59a1f-864a-4ccf-85e4-32a4c02a7ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Ë≠¶ÂëäÔºöÊ≠£Âú®‰ΩøÁî®Á§∫‰æãÂØÜÁ†ÅÔºåËØ∑Á´ãÂç≥Êõ¥Êîπ‰∏∫Ëá™Â∑±ÁöÑÂØÜÁ†ÅÔºÅ\n",
      "‚úÖ ‰æõÂ∫îÂïÜIDÂîØ‰∏ÄÁ∫¶ÊùüÂ∑≤ÁîüÊïà\n",
      "üìä ÂÖ±ÂèëÁé∞ 15 Êù°‰æõÂ∫îÂïÜËÆ∞ÂΩï\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÂØºÂÖ•ËøõÂ∫¶: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 15/15 [00:00<00:00, 52.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ ÂØºÂÖ•ÂÆåÊàêÔºÅÊñ∞Â¢û 15 Êù°ËÆ∞ÂΩï\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm  # ËøõÂ∫¶Êù°ÊîØÊåÅ\n",
    "\n",
    "# ÂÆâÂÖ®ÈÖçÁΩÆÔºàÂº∫ÁÉàÂª∫ËÆÆÈÄöËøáÁéØÂ¢ÉÂèòÈáèËÆæÁΩÆÂØÜÁ†ÅÔºâ\n",
    "NEO4J_URI = \"neo4j+s://68689680.databases.neo4j.io\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\") or \"IubLSzByNDoUMEg_LCBZe9zQ_DXZuzNubNX8QL_lyO0\"\n",
    "\n",
    "class SupplierImporter:\n",
    "    def __init__(self):\n",
    "        # ÈÖçÁΩÆËøûÊé•Ê±†Ôºà‰ºòÂåñÊÄßËÉΩÔºâ\n",
    "        self.driver = GraphDatabase.driver(\n",
    "            NEO4J_URI,\n",
    "            auth=(NEO4J_USER, NEO4J_PASSWORD),\n",
    "            max_connection_pool_size=10,\n",
    "            connection_timeout=30  # 30ÁßíËøûÊé•Ë∂ÖÊó∂\n",
    "        )\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def setup_constraints(self):\n",
    "        \"\"\"ËÆæÁΩÆÊï∞ÊçÆÂ∫ìÁ∫¶ÊùüÔºàÂπÇÁ≠âÊìç‰ΩúÔºâ\"\"\"\n",
    "        with self.driver.session(database=\"neo4j\") as session:\n",
    "            result = session.run(\"\"\"\n",
    "                CREATE CONSTRAINT supplier_id_unique IF NOT EXISTS\n",
    "                FOR (s:Supplier) REQUIRE s.SupplierID IS UNIQUE\n",
    "                \"\"\")\n",
    "            summary = result.consume()\n",
    "            print(\"‚úÖ ‰æõÂ∫îÂïÜIDÂîØ‰∏ÄÁ∫¶ÊùüÂ∑≤ÁîüÊïà\")\n",
    "\n",
    "    def preprocess_data(self, file_path):\n",
    "        \"\"\"Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÁÆ°ÈÅì\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, keep_default_na=False)\n",
    "            \n",
    "            # Â≠óÊÆµÊ†áÂáÜÂåñ\n",
    "            df.columns = df.columns.str.strip().str.replace(' ', '')\n",
    "            \n",
    "            # Á©∫ÂÄºÂ§ÑÁêÜÔºàÂ∞ÜÁ©∫Â≠óÁ¨¶‰∏≤ÂíåNaNÁªü‰∏Ä‰∏∫NoneÔºâ\n",
    "            df = df.replace(['', 'NULL', 'null', pd.NA], None)\n",
    "            \n",
    "            # URLÂ≠óÊÆµÈ¢ÑÂ§ÑÁêÜ\n",
    "            if 'HomePage' in df.columns:\n",
    "                df['HomePage'] = df['HomePage'].apply(\n",
    "                    lambda x: x if pd.isna(x) or x.startswith(('http://', 'https://')) \n",
    "                    else f'http://{x}'\n",
    "                )\n",
    "            \n",
    "            # È™åËØÅÂøÖÈúÄÂ≠óÊÆµ\n",
    "            required_fields = {'SupplierID', 'CompanyName'}\n",
    "            missing_fields = required_fields - set(df.columns)\n",
    "            if missing_fields:\n",
    "                raise ValueError(f\"Áº∫Â∞ëÂøÖÈúÄÂ≠óÊÆµ: {missing_fields}\")\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÂ§±Ë¥•: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def batch_import(self, df, batch_size=500):\n",
    "        \"\"\"È´òÊïàÊâπÈáèÂØºÂÖ•\"\"\"\n",
    "        total_records = len(df)\n",
    "        print(f\"üìä ÂÖ±ÂèëÁé∞ {total_records} Êù°‰æõÂ∫îÂïÜËÆ∞ÂΩï\")\n",
    "        \n",
    "        with self.driver.session(database=\"neo4j\") as session:\n",
    "            # ‰ΩøÁî®UNWINDÊâπÈáèÊìç‰Ωú\n",
    "            query = \"\"\"\n",
    "            UNWIND $batch AS supplier\n",
    "            MERGE (s:Supplier {SupplierID: supplier.SupplierID})\n",
    "            ON CREATE SET\n",
    "                s.CompanyName = supplier.CompanyName,\n",
    "                s.ContactName = supplier.ContactName,\n",
    "                s.ContactTitle = supplier.ContactTitle,\n",
    "                s.Address = supplier.Address,\n",
    "                s.City = supplier.City,\n",
    "                s.Region = supplier.Region,\n",
    "                s.PostalCode = supplier.PostalCode,\n",
    "                s.Country = supplier.Country,\n",
    "                s.Phone = supplier.Phone,\n",
    "                s.Fax = supplier.Fax,\n",
    "                s.HomePage = supplier.HomePage\n",
    "            RETURN count(s)\n",
    "            \"\"\"\n",
    "            \n",
    "            inserted = 0\n",
    "            with tqdm(total=total_records, desc=\"ÂØºÂÖ•ËøõÂ∫¶\") as pbar:\n",
    "                for i in range(0, total_records, batch_size):\n",
    "                    batch = df.iloc[i:i+batch_size].to_dict('records')\n",
    "                    result = session.run(query, {\"batch\": batch})\n",
    "                    inserted += result.single()[0]\n",
    "                    pbar.update(len(batch))\n",
    "            \n",
    "            print(f\"üéâ ÂØºÂÖ•ÂÆåÊàêÔºÅÊñ∞Â¢û {inserted} Êù°ËÆ∞ÂΩï\")\n",
    "            if duplicates := total_records - inserted:\n",
    "                print(f\"‚ö†Ô∏è  Ë∑≥Ëøá {duplicates} Êù°ÈáçÂ§çËÆ∞ÂΩï\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # ÂàùÂßãÂåñÂØºÂÖ•Âô®ÔºàËá™Âä®ÁÆ°ÁêÜËøûÊé•Ôºâ\n",
    "        with SupplierImporter() as importer:\n",
    "            # 1. ËÆæÁΩÆÁ∫¶Êùü\n",
    "            importer.setup_constraints()\n",
    "            \n",
    "            # 2. Âä†ËΩΩÂπ∂È¢ÑÂ§ÑÁêÜÊï∞ÊçÆ\n",
    "            df = importer.preprocess_data(\"exported_data/suppliers.csv\")\n",
    "            \n",
    "            # 3. ÊâßË°åÊâπÈáèÂØºÂÖ•\n",
    "            importer.batch_import(df, batch_size=1000)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ÂØºÂÖ•Â§±Ë¥•: {str(e)}\")\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ÂÆâÂÖ®Ë≠¶ÂëäÊ£ÄÊü•\n",
    "    if NEO4J_PASSWORD == \"IubLSzByNDoUMEg_LCBZe9zQ_DXZuzNubNX8QL_lyO0\":\n",
    "        print(\"‚ö†Ô∏è Ë≠¶ÂëäÔºöÊ≠£Âú®‰ΩøÁî®Á§∫‰æãÂØÜÁ†ÅÔºåËØ∑Á´ãÂç≥Êõ¥Êîπ‰∏∫Ëá™Â∑±ÁöÑÂØÜÁ†ÅÔºÅ\")\n",
    "    \n",
    "    exit(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f360ec-a6c0-4147-b9ba-69fe66c45e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f9fe97d-b6b4-4eef-a81c-d4b83fb4015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Ë≠¶ÂëäÔºöËØ∑Á´ãÂç≥Êõ¥ÊîπÈªòËÆ§ÂØÜÁ†ÅÔºÅ\n",
      "‚úÖ ÂàÜÁ±ªIDÂîØ‰∏ÄÁ∫¶ÊùüÂ∑≤ÂàõÂª∫\n",
      "üìã ÂÖ±ÂèëÁé∞ 20 Êù°ÂàÜÁ±ªËÆ∞ÂΩï\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÂØºÂÖ•ËøõÂ∫¶: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20/20 [00:00<00:00, 75.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ ÊàêÂäüÂØºÂÖ• 20 Êù°ÂàÜÁ±ªÊï∞ÊçÆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm  # ËøõÂ∫¶Êù°ÊîØÊåÅ\n",
    "\n",
    "# ÂÆâÂÖ®ÈÖçÁΩÆÔºàÂª∫ËÆÆÈÄöËøáÁéØÂ¢ÉÂèòÈáèËÆæÁΩÆÂØÜÁ†ÅÔºâ\n",
    "NEO4J_URI = \"neo4j+s://68689680.databases.neo4j.io\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\") or \"IubLSzByNDoUMEg_LCBZe9zQ_DXZuzNubNX8QL_lyO0\"\n",
    "\n",
    "class CategoryImporter:\n",
    "    def __init__(self):\n",
    "        self.driver = GraphDatabase.driver(\n",
    "            NEO4J_URI,\n",
    "            auth=(NEO4J_USER, NEO4J_PASSWORD),\n",
    "            max_connection_pool_size=5,\n",
    "            connection_timeout=15\n",
    "        )\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def setup_constraints(self):\n",
    "        \"\"\"ÂàõÂª∫CategoryIDÂîØ‰∏ÄÁ∫¶Êùü\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            result = session.run(\"\"\"\n",
    "                CREATE CONSTRAINT category_id_unique IF NOT EXISTS\n",
    "                FOR (c:Category) REQUIRE c.CategoryID IS UNIQUE\n",
    "                \"\"\")\n",
    "            print(\"‚úÖ ÂàÜÁ±ªIDÂîØ‰∏ÄÁ∫¶ÊùüÂ∑≤ÂàõÂª∫\")\n",
    "\n",
    "    def preprocess_data(self, file_path):\n",
    "        \"\"\"Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # ÂàóÂêçÊ†áÂáÜÂåñ\n",
    "            df.columns = df.columns.str.strip()\n",
    "            \n",
    "            # Á©∫ÂÄºÂ§ÑÁêÜ\n",
    "            df = df.replace(['', 'NULL', pd.NA], None)\n",
    "            \n",
    "            # È™åËØÅÂøÖÈúÄÂ≠óÊÆµ\n",
    "            required = {'CategoryID', 'CategoryName'}\n",
    "            missing = required - set(df.columns)\n",
    "            if missing:\n",
    "                raise ValueError(f\"Áº∫Â∞ëÂøÖÈúÄÂ≠óÊÆµ: {missing}\")\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÂ§±Ë¥•: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def import_categories(self, df):\n",
    "        \"\"\"ÊâßË°åÊï∞ÊçÆÂØºÂÖ•\"\"\"\n",
    "        total = len(df)\n",
    "        print(f\"üìã ÂÖ±ÂèëÁé∞ {total} Êù°ÂàÜÁ±ªËÆ∞ÂΩï\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # È´òÊïàÊâπÈáèÂØºÂÖ•Êü•ËØ¢\n",
    "            query = \"\"\"\n",
    "            UNWIND $categories AS cat\n",
    "            MERGE (c:Category {CategoryID: cat.CategoryID})\n",
    "            ON CREATE SET\n",
    "                c.CategoryName = cat.CategoryName,\n",
    "                c.Description = cat.Description\n",
    "            RETURN count(c)\n",
    "            \"\"\"\n",
    "            \n",
    "            # ÂàÜÊâπÂ§ÑÁêÜÔºàÊØèÊâπ1000Êù°Ôºâ\n",
    "            inserted = 0\n",
    "            batch_size = 1000\n",
    "            \n",
    "            with tqdm(total=total, desc=\"ÂØºÂÖ•ËøõÂ∫¶\") as pbar:\n",
    "                for i in range(0, total, batch_size):\n",
    "                    batch = df.iloc[i:i+batch_size].to_dict('records')\n",
    "                    result = session.run(query, {\"categories\": batch})\n",
    "                    inserted += result.single()[0]\n",
    "                    pbar.update(len(batch))\n",
    "            \n",
    "            print(f\"üéâ ÊàêÂäüÂØºÂÖ• {inserted} Êù°ÂàÜÁ±ªÊï∞ÊçÆ\")\n",
    "            if duplicates := total - inserted:\n",
    "                print(f\"‚ö†Ô∏è  Ë∑≥Ëøá {duplicates} Êù°ÈáçÂ§çËÆ∞ÂΩï\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # ÂØÜÁ†ÅÂÆâÂÖ®Ê£ÄÊü•\n",
    "        if \"IubLSzByNDoUMEg\" in NEO4J_PASSWORD:\n",
    "            print(\"‚ö†Ô∏è Ë≠¶ÂëäÔºöËØ∑Á´ãÂç≥Êõ¥ÊîπÈªòËÆ§ÂØÜÁ†ÅÔºÅ\")\n",
    "        \n",
    "        with CategoryImporter() as importer:\n",
    "            # 1. ËÆæÁΩÆÁ∫¶Êùü\n",
    "            importer.setup_constraints()\n",
    "            \n",
    "            # 2. Âä†ËΩΩÊï∞ÊçÆ\n",
    "            df = importer.preprocess_data(\"exported_data/categories.csv\")\n",
    "            \n",
    "            # 3. ÊâßË°åÂØºÂÖ•\n",
    "            importer.import_categories(df)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ÂØºÂÖ•Â§±Ë¥•: {str(e)}\")\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exit(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94929f6c-b5d2-4661-97f7-51f77fec6cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è ÂÆâÂÖ®Ë≠¶ÂëäÔºöËØ∑Á´ãÂç≥Êõ¥ÊîπÈªòËÆ§Êï∞ÊçÆÂ∫ìÂØÜÁ†ÅÔºÅ\n",
      "‚úÖ Êï∞ÊçÆÂ∫ìÁ∫¶ÊùüÂíåÁ¥¢ÂºïÂ∑≤Â∞±Áª™\n",
      "üìä ÂÖ±ÂèëÁé∞ 10 Êù°‰∫ßÂìÅËÆ∞ÂΩï\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ÂØºÂÖ•ËøõÂ∫¶: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00<00:00, 33.88product/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÊàêÂäüÂØºÂÖ• 10 Êù°‰∫ßÂìÅÊï∞ÊçÆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ÂÆâÂÖ®ÈÖçÁΩÆÔºàÁîü‰∫ßÁéØÂ¢ÉÂª∫ËÆÆ‰ΩøÁî®ÁéØÂ¢ÉÂèòÈáèÔºâ\n",
    "NEO4J_URI = \"neo4j+s://68689680.databases.neo4j.io\"\n",
    "NEO4J_USER = \"neo4j\"\n",
    "NEO4J_PASSWORD = os.getenv(\"NEO4J_PASSWORD\") or \"IubLSzByNDoUMEg_LCBZe9zQ_DXZuzNubNX8QL_lyO0\"\n",
    "\n",
    "class ProductImporter:\n",
    "    def __init__(self):\n",
    "        self.driver = GraphDatabase.driver(\n",
    "            NEO4J_URI,\n",
    "            auth=(NEO4J_USER, NEO4J_PASSWORD),\n",
    "            max_connection_pool_size=8,\n",
    "            connection_acquisition_timeout=30\n",
    "        )\n",
    "    \n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        self.driver.close()\n",
    "    \n",
    "    def setup_schema(self):\n",
    "        \"\"\"ÂàõÂª∫ÂîØ‰∏ÄÁ∫¶ÊùüÂíåÁ¥¢Âºï\"\"\"\n",
    "        with self.driver.session() as session:\n",
    "            # ÂàõÂª∫ÂîØ‰∏ÄÁ∫¶Êùü\n",
    "            session.run(\"\"\"\n",
    "                CREATE CONSTRAINT product_id_unique IF NOT EXISTS\n",
    "                FOR (p:Product) REQUIRE p.ProductID IS UNIQUE\n",
    "                \"\"\")\n",
    "            \n",
    "            # ‰∏∫Â∏∏Áî®Êü•ËØ¢Â≠óÊÆµÂàõÂª∫Á¥¢Âºï\n",
    "            session.run(\"\"\"\n",
    "                CREATE INDEX product_name_index IF NOT EXISTS\n",
    "                FOR (p:Product) ON (p.ProductName)\n",
    "                \"\"\")\n",
    "            \n",
    "            print(\"‚úÖ Êï∞ÊçÆÂ∫ìÁ∫¶ÊùüÂíåÁ¥¢ÂºïÂ∑≤Â∞±Áª™\")\n",
    "\n",
    "    def preprocess_products(self, file_path):\n",
    "        \"\"\"Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÁÆ°ÈÅì\"\"\"\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, keep_default_na=False)\n",
    "            \n",
    "            # ÂàóÂêçÊ†áÂáÜÂåñ\n",
    "            df.columns = df.columns.str.strip()\n",
    "            \n",
    "            # Á±ªÂûãËΩ¨Êç¢\n",
    "            numeric_cols = ['UnitPrice', 'UnitsInStock', 'UnitsOnOrder', 'ReorderLevel']\n",
    "            for col in numeric_cols:\n",
    "                if col in df.columns:\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            # Â∏ÉÂ∞îÂÄºÂ§ÑÁêÜ\n",
    "            if 'Discontinued' in df.columns:\n",
    "                df['Discontinued'] = df['Discontinued'].astype(bool)\n",
    "            \n",
    "            # Á©∫ÂÄºÂ§ÑÁêÜ\n",
    "            df = df.replace(['', 'NULL', 'null', pd.NA], None)\n",
    "            \n",
    "            # È™åËØÅÂøÖÈúÄÂ≠óÊÆµ\n",
    "            required = {'ProductID', 'ProductName'}\n",
    "            missing = required - set(df.columns)\n",
    "            if missing:\n",
    "                raise ValueError(f\"CSVÊñá‰ª∂Áº∫Â∞ëÂøÖÈúÄÂ≠óÊÆµ: {missing}\")\n",
    "            \n",
    "            return df\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÈîôËØØ: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def batch_import(self, df, batch_size=2000):\n",
    "        \"\"\"È´òÊïàÊâπÈáèÂØºÂÖ•\"\"\"\n",
    "        total = len(df)\n",
    "        print(f\"üìä ÂÖ±ÂèëÁé∞ {total} Êù°‰∫ßÂìÅËÆ∞ÂΩï\")\n",
    "        \n",
    "        with self.driver.session() as session:\n",
    "            # ‰ΩøÁî®ÂèÇÊï∞ÂåñÊü•ËØ¢Èò≤Ê≠¢Ê≥®ÂÖ•\n",
    "            query = \"\"\"\n",
    "            UNWIND $products AS p\n",
    "            MERGE (prod:Product {ProductID: p.ProductID})\n",
    "            ON CREATE SET\n",
    "                prod.ProductName = p.ProductName,\n",
    "                prod.QuantityPerUnit = p.QuantityPerUnit,\n",
    "                prod.UnitPrice = toFloat(p.UnitPrice),\n",
    "                prod.UnitsInStock = toInteger(p.UnitsInStock),\n",
    "                prod.UnitsOnOrder = toInteger(p.UnitsOnOrder),\n",
    "                prod.ReorderLevel = toInteger(p.ReorderLevel),\n",
    "                prod.Discontinued = p.Discontinued\n",
    "            RETURN count(prod)\n",
    "            \"\"\"\n",
    "            \n",
    "            inserted = 0\n",
    "            with tqdm(total=total, desc=\"ÂØºÂÖ•ËøõÂ∫¶\", unit=\"product\") as pbar:\n",
    "                for i in range(0, total, batch_size):\n",
    "                    batch = df.iloc[i:i+batch_size].to_dict('records')\n",
    "                    result = session.run(query, {\"products\": batch})\n",
    "                    inserted += result.single()[0]\n",
    "                    pbar.update(len(batch))\n",
    "            \n",
    "            print(f\"‚úÖ ÊàêÂäüÂØºÂÖ• {inserted} Êù°‰∫ßÂìÅÊï∞ÊçÆ\")\n",
    "            if duplicates := total - inserted:\n",
    "                print(f\"‚ö†Ô∏è  Ë∑≥Ëøá {duplicates} Êù°ÈáçÂ§çËÆ∞ÂΩï\")\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        # ÂØÜÁ†ÅÂÆâÂÖ®Ê£ÄÊü•\n",
    "        if NEO4J_PASSWORD.startswith(\"IubLSz\"):\n",
    "            print(\"‚ö†Ô∏è ÂÆâÂÖ®Ë≠¶ÂëäÔºöËØ∑Á´ãÂç≥Êõ¥ÊîπÈªòËÆ§Êï∞ÊçÆÂ∫ìÂØÜÁ†ÅÔºÅ\")\n",
    "        \n",
    "        with ProductImporter() as importer:\n",
    "            # 1. ÂàùÂßãÂåñÊï∞ÊçÆÂ∫ìschema\n",
    "            importer.setup_schema()\n",
    "            \n",
    "            # 2. Âä†ËΩΩÂπ∂È¢ÑÂ§ÑÁêÜÊï∞ÊçÆ\n",
    "            df = importer.preprocess_products(\"exported_data/products.csv\")\n",
    "            \n",
    "            # 3. ÊâßË°åÊâπÈáèÂØºÂÖ•\n",
    "            importer.batch_import(df, batch_size=1500)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Ëá¥ÂëΩÈîôËØØ: {str(e)}\")\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    exit(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b743856-617c-4c37-9bd4-6c5f9ba41669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100e8175-2193-4f87-ae00-37f15968064e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8adddc75-823a-4340-bcb3-e320bb6869ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported 15 nodes from data/neo4j_admin/supplier_nodes.csv with label Supplier\n",
      "Imported 10 nodes from data/neo4j_admin/shipper_nodes.csv with label Shipper\n",
      "Imported 30 nodes from data/neo4j_admin/review_nodes.csv with label Review\n",
      "Imported 10 nodes from data/neo4j_admin/product_nodes.csv with label Product\n",
      "Imported 100 nodes from data/neo4j_admin/order_nodes.csv with label Order\n",
      "Imported 3 nodes from data/neo4j_admin/employee_nodes.csv with label Employee\n",
      "Imported 20 nodes from data/neo4j_admin/customer_nodes.csv with label Customer\n",
      "Imported 20 nodes from data/neo4j_admin/category_nodes.csv with label Category\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12341/3191131646.py:78: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  start_id = row[0]\n",
      "/tmp/ipykernel_12341/3191131646.py:79: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  end_id = row[1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 161\u001b[0m\n\u001b[1;32m    159\u001b[0m importer \u001b[38;5;241m=\u001b[39m Neo4jImporter(uri, user, password)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[43mimporter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_files\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     importer\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[0;32mIn[2], line 83\u001b[0m, in \u001b[0;36mNeo4jImporter.import_data\u001b[0;34m(self, node_files, edge_files)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Handle additional properties\u001b[39;00m\n\u001b[1;32m     82\u001b[0m props \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m additional_props:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prop \u001b[38;5;129;01min\u001b[39;00m additional_props:\n\u001b[1;32m     85\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pd\u001b[38;5;241m.\u001b[39misna(row[prop]):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/indexes/base.py:3197\u001b[0m, in \u001b[0;36mIndex.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3195\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   3196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m-> 3197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3198\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3199\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3200\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Index is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d03c116-777a-4eb7-89ec-96d58889ddda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
