from typing import List, Dict, AsyncGenerator, Optional, Callable
import aiohttp
import json
import re
from app.core.config import settings
from app.core.logger import get_logger

logger = get_logger(service="ollama")


class OllamaService:
    def __init__(self):
        logger.info("Initializing Ollama Service")
        self.base_url = settings.OLLAMA_BASE_URL
        self.chat_model = settings.OLLAMA_CHAT_MODEL
        self.reason_model = settings.OLLAMA_REASON_MODEL

    async def generate_stream(
            self,
            messages: List[Dict],
            user_id: Optional[int] = None,
            conversation_id: Optional[int] = None,
            on_complete: Optional[Callable] = None
    ) -> AsyncGenerator[str, None]:
        """æµå¼ç”Ÿæˆå›å¤"""
        try:
            model = self.reason_model
            logger.info(f"Using model: {model}")

            header = "### æ€è€ƒè¿‡ç¨‹\n\nğŸ¤” æ­£åœ¨æ·±åº¦æ€è€ƒâ€¦\n\n"
            safe_header = json.dumps(header, ensure_ascii=False)[1:-1]
            yield f"data: {safe_header}\n\n"

            full_response = [header]
            has_transitioned = False

            # ==========================================
            # 1. åˆå§‹åŒ–ç¼“å†²åŒºï¼Œç”¨äºè§£å†³å­—ç¬¦è¢«åˆ‡æ–­çš„é—®é¢˜
            # ==========================================
            text_buffer = ""

            async with aiohttp.ClientSession() as session:
                async with session.post(
                        f"{self.base_url}/api/chat",
                        json={
                            "model": model,
                            "messages": messages,
                            "stream": True,
                            "keep_alive": -1,
                            "options": {"temperature": 0.3}
                        }
                ) as response:
                    async for line in response.content:
                        if line:
                            try:
                                line_text = line.decode('utf-8').strip()
                                if not line_text: continue
                                chunk = json.loads(line_text)
                                message = chunk.get("message", {})

                                thinking = message.get("thinking", "")
                                content = message.get("content", "")

                                # æå–å½“å‰éœ€è¦å¤„ç†çš„æ–‡æœ¬ç‰‡æ®µ
                                current_text = ""
                                is_thinking = False

                                if thinking:
                                    current_text = thinking
                                    is_thinking = True
                                elif content:
                                    current_text = content
                                    is_thinking = False
                                else:
                                    continue

                                # ==========================================
                                # 2. ç¼“å†²åŒºæ‹¼æ¥é€»è¾‘ (æ ¸å¿ƒä¿®å¤)
                                # ==========================================
                                # å°†ä¸Šä¸€è½®å‰©ä¸‹çš„å°¾å·´æ‹¼æ¥åˆ°å½“å‰å¼€å¤´
                                if text_buffer:
                                    current_text = text_buffer + current_text
                                    text_buffer = ""  # æ¸…ç©ºç¼“å†²åŒº

                                # æ£€æŸ¥å½“å‰ç‰‡æ®µæ˜¯å¦ä»¥ "å±é™©å­—ç¬¦" ç»“å°¾
                                # å¦‚æœä»¥ \ ç»“å°¾ï¼Œè¯´æ˜å¯èƒ½æ˜¯ \[ æˆ– \( æˆ– \begin è¢«åˆ‡æ–­äº†
                                # å¦‚æœä»¥ [ ç»“å°¾ï¼Œè¯´æ˜å¯èƒ½æ˜¯ [\begin è¢«åˆ‡æ–­äº†
                                if current_text.endswith("\\") or current_text.endswith("["):
                                    # å°†æœ€åä¸€ä¸ªå­—ç¬¦æ‰£ç•™åˆ°ä¸‹ä¸€è½®
                                    text_buffer = current_text[-1]
                                    current_text = current_text[:-1]

                                    # å¦‚æœåˆ‡æ‰åä¸ºç©ºï¼Œè¿™è½®ç›´æ¥è·³è¿‡ï¼Œç­‰å¾…ä¸‹ä¸€è½®æ‹¼æ¥
                                    if not current_text:
                                        continue

                                # ==========================================
                                # 3. LaTeX å¤„ç†é€»è¾‘
                                # ==========================================
                                def process_latex(text):
                                    text = text.replace("\\[", "\n$$\n")
                                    text = text.replace("\\]", "\n$$\n")
                                    text = text.replace("\\(", "$")
                                    text = text.replace("\\)", "$")
                                    text = re.sub(r'\[\s*\\begin', '\n$$\n\\begin', text)
                                    text = re.sub(r'(\\end\{.*?\})\s*\]', r'\1\n$$\n', text)
                                    return text

                                # å¤„ç†é€»è¾‘
                                if is_thinking:
                                    proc_text = process_latex(current_text)
                                    full_response.append(proc_text)
                                    safe_text = json.dumps(proc_text, ensure_ascii=False)[1:-1]
                                    yield f"data: {safe_text}\n\n"
                                else:
                                    # æ€è€ƒç»“æŸçš„è½¬æ¢é€»è¾‘
                                    if not has_transitioned:
                                        has_transitioned = True
                                        finish_msg = "\n\nâœ… æ€è€ƒå®Œæˆ\n\n---\n\n"
                                        full_response.append(finish_msg)
                                        safe_finish = json.dumps(finish_msg, ensure_ascii=False)[1:-1]
                                        yield f"data: {safe_finish}\n\n"

                                    proc_text = process_latex(current_text)
                                    full_response.append(proc_text)
                                    safe_text = json.dumps(proc_text, ensure_ascii=False)[1:-1]
                                    yield f"data: {safe_text}\n\n"

                            except Exception as e:
                                logger.warning(f"Error parsing chunk: {e}")
                                continue

            # å¾ªç¯ç»“æŸåï¼Œå¦‚æœç¼“å†²åŒºé‡Œè¿˜æœ‰å‰©ä¸‹çš„å­—ç¬¦ï¼ˆæå…¶ç½•è§ï¼Œæ¯”å¦‚åˆšå¥½ä»¥ \ ç»“å°¾ç»“æŸå¯¹è¯ï¼‰ï¼Œä¾ç„¶è¦å‘å‡ºå»
            if text_buffer:
                safe_buffer = json.dumps(text_buffer, ensure_ascii=False)[1:-1]
                yield f"data: {safe_buffer}\n\n"
                full_response.append(text_buffer)

            if on_complete:
                await on_complete(user_id, conversation_id, messages, "".join(full_response))

        except Exception as e:
            logger.error(f"Stream generation error: {str(e)}", exc_info=True)
            err_msg = f"\n\nç”Ÿæˆå‡ºé”™: {str(e)}"
            safe_err = json.dumps(err_msg, ensure_ascii=False)[1:-1]
            yield f"data: {safe_err}\n\n"
            raise